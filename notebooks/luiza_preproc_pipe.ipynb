{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7cf9d4",
   "metadata": {},
   "source": [
    "# Limpeza de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42989a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fde8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09edccce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pkg_resources failed: Traceback (most recent call last):\n",
      "  File \"/home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/lsbpaiva/.pyenv/versions/3.8.12/lib/python3.8/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 604, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 843, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3095, in <module>\n",
      "    class RequirementParseError(packaging.requirements.InvalidRequirement):\n",
      "AttributeError: module 'pkg_resources._vendor.packaging' has no attribute 'requirements'\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'pt' are deprecated. Please use the\n",
      "full pipeline package name 'pt_core_news_sm' instead.\u001b[0m\n",
      "Collecting pt-core-news-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.3.0/pt_core_news_sm-3.3.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from pt-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: setuptools in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (62.3.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: jinja2 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.22.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (8.0.16)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (4.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2022.5.18.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lsbpaiva/.pyenv/versions/3.8.12/envs/twitterelectionbr/lib/python3.8/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->pt-core-news-sm==3.3.0) (2.1.1)\n",
      "Installing collected packages: pt-core-news-sm\n",
      "Successfully installed pt-core-news-sm-3.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8089f17a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3798/1274174624.py:1: DtypeWarning: Columns (1,2,5,6,7,8,9,10,11,12,13,14,15,16,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../raw_data/dilma.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../raw_data/dilma.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84557e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../raw_data/biroliro_total_tweets.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../raw_data/biroliro_total_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67d4cef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   url              5 non-null      object\n",
      " 1   date             5 non-null      object\n",
      " 2   content          5 non-null      object\n",
      " 3   id               5 non-null      int64 \n",
      " 4   reply_count      5 non-null      int64 \n",
      " 5   retweet_count    5 non-null      int64 \n",
      " 6   like_count       5 non-null      int64 \n",
      " 7   quote_count      5 non-null      int64 \n",
      " 8   lang             5 non-null      object\n",
      " 9   username         5 non-null      object\n",
      " 10  displayname      5 non-null      object\n",
      " 11  description      3 non-null      object\n",
      " 12  verified         5 non-null      bool  \n",
      " 13  created          5 non-null      object\n",
      " 14  followers_count  5 non-null      int64 \n",
      " 15  friends_count    5 non-null      int64 \n",
      " 16  location         5 non-null      object\n",
      " 17  protected        5 non-null      bool  \n",
      " 18  profile_img      5 non-null      object\n",
      "dtypes: bool(2), int64(7), object(10)\n",
      "memory usage: 818.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data.head().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddbfbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtro = df[(df.lang == 'pt') & (df.url.str.startswith('https'))]\n",
    "#df = filtro.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6b293e",
   "metadata": {},
   "source": [
    "## Transformadores Personalizados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa627f34",
   "metadata": {},
   "source": [
    "### Limpeza colunas de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56cf46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import  make_column_transformer\n",
    "import re \n",
    "\n",
    "class CleaningEncoder(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Receives raw text data from the tweets and returns clean, ready to process data:\n",
    "    turns all into lower case;\n",
    "    removes punctuation;\n",
    "    removes stopwords;\n",
    "    removes numbers;\n",
    "    removes users' handles\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "                        \n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        #assert isinstance(X, pd.DataFrame)\n",
    "        X_ = X.copy()      \n",
    "        \n",
    "        #removin NaN values\n",
    "        X_ = X_.fillna('nenhuma descrição')\n",
    "        \n",
    "        #removing links\n",
    "        X_ = X_.apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
    "        X_ = X_.apply(lambda x: re.sub(r\"www.\\S+\", \"\", x))\n",
    "                \n",
    "        #removing punctuation from each tweet\n",
    "        new_punc = list(string.punctuation)\n",
    "        del new_punc[2]\n",
    "        del new_punc[-11]\n",
    "        for punctuation in new_punc:\n",
    "            X_ = X_.str.replace(punctuation, '')\n",
    "            \n",
    "        #removing numbers\n",
    "        X_ = X_.str.replace('\\d+', '')\n",
    "        \n",
    "        #tokenizing - removes handles, applies lowercase, keeps #, shortens letter repetitions to three\n",
    "        #ex: kkkkk, kkkkkk, kkkkkkkkk = kkk\n",
    "        tkn = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "        X_ = X_.apply(lambda x: tkn.tokenize(x))\n",
    "        \n",
    "        #removing stopwords\n",
    "        stop_words = stopwords.words('portuguese')\n",
    "        stop_words.remove('não')\n",
    "        addicional = [\n",
    "            'ta', 'q', 'nao', 'tah', 'tao', 'eh', 'vc', 'voce',\n",
    "            'pq', 'quedê', 'mane', 'mto', 'mt', 'bj', 'bjs',\n",
    "            'b', 'sao', 'axo', 'mano', 'ae', 'neh', 'aí',\n",
    "            'kkk', 'porque', 'né', 'no']\n",
    "        stop_words.extend(addicional)\n",
    "        \n",
    "        X_ = X_.apply(lambda x: [word for word in x if word not in (stop_words)])\n",
    "        \n",
    "        return X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d1c77ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#.str.replace('\\d+', '')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#.str.replace('\\d+', '')\n",
    "X = data.content\n",
    "#X.str.lower()\n",
    "\n",
    "#dataframe['column_name']=dataframe['column_name'].apply(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d42465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27a7a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3798/2400588789.py:39: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  X_ = X_.str.replace(punctuation, '')\n",
      "/tmp/ipykernel_3798/2400588789.py:42: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  X_ = X_.str.replace('\\d+', '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                                                                [vai, acontecer, biroliro]\n",
       "1                                  [passei, min, metrô, cercada, macho, babaca, falando, biroliro, inferno]\n",
       "2       [tô, adotando, postura, ciro, pessoa, vem, tentar, convencer, biroliro, não, facista, mando, “, ...\n",
       "3                         [facil, pro, eleitor, indeciso, escolher, ciro, haddad, biroliro, segundo, turno]\n",
       "4                                                   [rompendo, laços, familiares, causa, biroliro, #sextou]\n",
       "                                                       ...                                                 \n",
       "3530                                                                 [ousam, dizer, homem, igual, biroliro]\n",
       "3531                                                           [biroliro, bonoro, bozonaro, bololo, boniro]\n",
       "3532                                             [pronto, achei, melhor, apelido, pro, salnorabo, biroliro]\n",
       "3533                                                                     [pessoal, biroliro, chegou, credo]\n",
       "3534                                                    [tô, tipo, dias, falar, irmão, causa, biroliro, rs]\n",
       "Name: content, Length: 3535, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = CleaningEncoder()\n",
    "X_clean = clean.fit_transform(X)\n",
    "\n",
    "X_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1676c4",
   "metadata": {},
   "source": [
    "### Transformação da data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92803390",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEncoder(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    Transforms the date column from string to datetime object \n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_ = X.copy()\n",
    "        X_ = X_.apply(lambda x: pd.to_datetime(x))\n",
    "        X_ = pd.DataFrame(X_)\n",
    "        X_['data'] = X_['date'].dt.date\n",
    "        X_['hora'] = X_['date'].dt.time\n",
    "        X_.drop(columns = 'date', inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ffa29fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data['date']\n",
    "timer = TimeEncoder()\n",
    "result = timer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3543510f",
   "metadata": {},
   "source": [
    "# Função latitude longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87ad3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../raw_data/vader_nlp_datasets/#haddad_vader.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ac536f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "33849555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent = \"my project app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8c4b3de9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_754/1171173744.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  teste.location.fillna('Brasil', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.location.fillna('Brasil', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "65046955",
   "metadata": {},
   "outputs": [],
   "source": [
    "dado_teste.location.fillna('Brasil', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.location = data.location.replace('','Brasil' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eb58aea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brasil                    5580\n",
       "São Paulo, Brasil          737\n",
       "Rio de Janeiro, Brasil     509\n",
       "São Paulo                  506\n",
       "Rio de Janeiro             355\n",
       "                          ... \n",
       "Porto Alegre, Paris          1\n",
       "Por Aí                       1\n",
       "BH, Brazil                   1\n",
       "Ipupiara, Brasil             1\n",
       "Nova Iguaçu - RJ             1\n",
       "Name: location, Length: 3015, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8ed08821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent = \"my project app\")\n",
    "\n",
    "def find_location(location):\n",
    "    dados['location'].fillna('Brasil', inplace=True)\n",
    "    \n",
    "    try:\n",
    "        local  = geolocator.geocode(location).point\n",
    "        latitude = local[0]\n",
    "        longitude = local[1]\n",
    "    except:\n",
    "        latitude = -10.3333333\n",
    "        longitude = -53.2\n",
    "    return latitude, longitude\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "152f65d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def location_ready(dados):\n",
    "    results = dados.location.apply(lambda x: find_location(x))\n",
    "    dados[['latitude', 'longitude']] = pd.DataFrame(results.to_list())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
